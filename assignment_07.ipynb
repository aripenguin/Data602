{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGRMTNiN2j3JD45Uo4M4i3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aripenguin/Data602/blob/main/assignment_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 7**  \n",
        "# **Weeks 8 & 9 - Pandas**  \n",
        "\n",
        "**Introduction**  \n",
        "The data I am using is *Parks Inspection Program – Daily Immediate Attentions* from NYC Open Data (https://data.cityofnewyork.us/City-Government/Parks-Inspection-Program-Daily-Immediate-Attention/s6dm-mdan/about_data). This dataset from the NYC Department of Parks and Recreation contains immediante attention hazards such as hateful graffiti or _. I choose this dataset because I wanted to put something from the NYC Open Data as local data sounded interesting to me. I wanted to look up datasets by departments and choose to check from Department of the Parks and Recreation because I am a big fan of the series Parks and Recreation. This one sound interesting and after downloading it, I really wanted to clean it up.\n",
        "\n",
        "**Data Exploration**  "
      ],
      "metadata": {
        "id": "JG2GQl8HpUUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/aripenguin/Data602/main/Parks_Inspection_Program___Daily_Immediate_Attentions_20240323.csv'\n",
        "parks_hazards = pd.read_csv(url)\n",
        "\n",
        "print(\"There are {} columns in this Daily Immediate Attentions dataset.\".format(parks_hazards.shape[1]))\n",
        "print(\"The column names are: {}\".format(list(parks_hazards)))\n",
        "print(\"There are {} rows in this Daily Immediate Attentions dataset.\".format(parks_hazards.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZePpfEMGbSe",
        "outputId": "7de342dc-7863-41dc-8808-e9aa1695f418"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 13 columns in this Daily Immediate Attentions dataset.\n",
            "The column names are: ['Type', 'Inspection ID', 'Type Key', 'LastFieldInspectionDate', 'DateTimeEntered', 'iaAddedDate', 'OtherComments', 'Priority', 'Feature', 'WorkOrderNumber', 'Extended', 'SignedOff', 'orgtbl']\n",
            "There are 94133 rows in this Daily Immediate Attentions dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-ac33202cb8c8>:4: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  parks_hazards = pd.read_csv(url)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is an example of what the rows in the Daily Immediate Attentions dataset looks like.\n",
        "\n",
        "As you can see, there are five columns (LastFieldInspectionDate, DateTimeEntered, OtherComments, WorkOrderNumber, SignedOff) that have some missing values.\n",
        "\n",
        "Something else to note that can be cleaned is the last two columns (SignedOff, orgtbl). They hold the same data, whether or not the issue is resolved or not. This means they can be combined later."
      ],
      "metadata": {
        "id": "xKbcpqKyQMlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(parks_hazards.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2H4qfC6QXF2",
        "outputId": "35101924-3c5a-4812-bb80-48ec9f5dc25c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of       Type  Inspection ID  Type Key LastFieldInspectionDate  \\\n",
            "0       IA         176318    157665                     NaN   \n",
            "1       IA         180483    161535                     NaN   \n",
            "2       IA         177264    158684                     NaN   \n",
            "3       IA         176927    158258                     NaN   \n",
            "4       IA         141753    123269                     NaN   \n",
            "...    ...            ...       ...                     ...   \n",
            "94128   IA         181250    162221     2023-12-20T00:00:00   \n",
            "94129   IA         181357    162341     2023-12-21T00:00:00   \n",
            "94130   IA         181439    162417     2023-12-21T00:00:00   \n",
            "94131   IA         181457    162434     2024-01-11T00:00:00   \n",
            "94132   IA         181568    162522     2024-01-03T00:00:00   \n",
            "\n",
            "               DateTimeEntered              iaAddedDate  \\\n",
            "0                          NaN  2023-04-13 23:00:00.000   \n",
            "1                          NaN  2023-10-26 23:00:00.000   \n",
            "2                          NaN  2023-06-01 23:00:00.000   \n",
            "3                          NaN  2023-05-11 23:00:00.000   \n",
            "4                          NaN  2021-01-06 23:00:00.000   \n",
            "...                        ...                      ...   \n",
            "94128  2023-12-20 13:45:31.537  2023-12-08 23:00:00.000   \n",
            "94129  2023-12-21 13:12:18.550  2023-12-15 23:00:00.000   \n",
            "94130  2023-12-26 06:57:17.360  2023-12-20 23:00:00.000   \n",
            "94131  2024-01-12 06:25:13.700  2023-12-20 23:00:00.000   \n",
            "94132  2024-01-03 13:37:13.810  2023-12-28 23:00:00.000   \n",
            "\n",
            "                                           OtherComments Priority  \\\n",
            "0                                                    NaN        2   \n",
            "1                                                    NaN        2   \n",
            "2                                                    NaN        2   \n",
            "3                                                    NaN        2   \n",
            "4                                                    NaN        2   \n",
            "...                                                  ...      ...   \n",
            "94128           - Vincent.Piccolo(12/20/2023 1:45:31 PM)        2   \n",
            "94129  - Brian.Tobias(12/18/2023 8:15:32 AM) - Llanos...        2   \n",
            "94130            - Kermyt.Padilla(12/26/2023 6:57:17 AM)        1   \n",
            "94131  Back Filled With 1 Bag of Cold Patch - Armand....        2   \n",
            "94132  Litter picked - Khalil.Bratton(1/3/2024 1:37:1...        2   \n",
            "\n",
            "              Feature WorkOrderNumber  Extended SignedOff      orgtbl  \n",
            "0               Trees             NaN     False       NaN  Unresolved  \n",
            "1      Paved Surfaces             NaN      True       NaN  Unresolved  \n",
            "2      Paved Surfaces             NaN      True       NaN  Unresolved  \n",
            "3      Paved Surfaces             NaN     False       NaN  Unresolved  \n",
            "4      Paved Surfaces             NaN      True       NaN  Unresolved  \n",
            "...               ...             ...       ...       ...         ...  \n",
            "94128           Trees             NaN     False      True    Resolved  \n",
            "94129  Paved Surfaces         2500950     False      True    Resolved  \n",
            "94130           Trees             NaN     False      True    Resolved  \n",
            "94131  Paved Surfaces             NaN     False      True    Resolved  \n",
            "94132          Litter             NaN     False      True    Resolved  \n",
            "\n",
            "[94133 rows x 13 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary statistics**  \n",
        " There isn't a lot of columns that would be worth doing numerical summary statistics in this dataset.\n",
        "\n",
        " For the priority column, we have three options for data (Z, 1, 2).  \n",
        " First, I will change all the Z/zero priority to 0 and save all the data in this column to type integer so we can look at the mean, median, and quantiles.\n",
        "\n",
        " I will revisit summary statistics for a new column I wish to make later.  \n"
      ],
      "metadata": {
        "id": "SXvBGAMXSeJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parks_hazards.loc[parks_hazards['Priority'] == 'Z', 'Priority'] = 0\n",
        "parks_hazards['Priority'] = pd.to_numeric(parks_hazards['Priority'], errors='coerce', downcast='integer')\n",
        "#parks_hazards['Priority'] = parks_hazards['Priority'].astype(int)\n",
        "print(parks_hazards.loc[101,:])\n",
        "\n",
        "print(\"The mean of the Priority column: {}\".format(parks_hazards['Priority'].mean()))\n",
        "print(\"The median of the Priority column: {}\".format(parks_hazards['Priority'].median()))\n",
        "print(\"The quantiles of the Priority column: \\n{}\".format(parks_hazards['Priority'].quantile([.1, .25, .5, .75])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Cis9WCVpXP",
        "outputId": "f6dd5b6e-fdbc-4c2e-ffd1-d90cc2605b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type                                      Graffiti\n",
            "Inspection ID                                55038\n",
            "Type Key                                    142577\n",
            "LastFieldInspectionDate        2007-11-05T00:00:00\n",
            "DateTimeEntered            2008-04-24 13:44:58.140\n",
            "iaAddedDate                2022-05-03 23:00:00.000\n",
            "OtherComments                                  NaN\n",
            "Priority                                       0.0\n",
            "Feature                                   Graffiti\n",
            "WorkOrderNumber                                NaN\n",
            "Extended                                     False\n",
            "SignedOff                                     True\n",
            "orgtbl                                    Resolved\n",
            "Name: 101, dtype: object\n",
            "The mean of the Priority column: 1.8791819980007232\n",
            "The median of the Priority column: 2.0\n",
            "The quantiles of the Priority column: \n",
            "0.10    2.0\n",
            "0.25    2.0\n",
            "0.50    2.0\n",
            "0.75    2.0\n",
            "Name: Priority, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Wrangling**  \n",
        "\n",
        "Instead of working with 94,133 rows, I will subset this dataset to 10,000 rows to make it easier to work with.\n",
        "\n"
      ],
      "metadata": {
        "id": "3Y1tvoTnZsIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#subset to 10,000\n",
        "parks_hazards_subset = parks_hazards.sample(n = 10000)\n",
        "\n",
        "print(\"1. Modify multiple column names.\")\n",
        "#organized the names of the date columns to match and DateTimeEntered did not describe the column well (column is for last action to address the hazard)\n",
        "#Inspection ID and Type Key are modified to match the other names (no spaces)\n",
        "parks_hazards_subset.rename(columns = {'DateTimeEntered':'LastActionDate', 'iaAddedDate':'AddedDate', 'Inspection ID':'InspectionID', 'Type Key':'TypeKey'}, inplace = True)\n",
        "print(list(parks_hazards_subset))\n",
        "\n",
        "print(\"\\n2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\")\n",
        "print(parks_hazards_subset.dtypes)\n",
        "#Priority is set as a string but should be numeric\n",
        "parks_hazards_subset['Priority'] = pd.to_numeric(parks_hazards_subset['Priority'], errors='coerce', downcast='integer')\n",
        "#SignedOff is set as a string but should be a bool with the empty rows being False\n",
        "parks_hazards_subset.loc[parks_hazards_subset['SignedOff'] != None, 'SignedOff'] = True\n",
        "parks_hazards_subset['SignedOff'].fillna(False, inplace = True)\n",
        "#all three date columns are not set as datetime\n",
        "import datetime\n",
        "parks_hazards_subset['LastFieldInspectionDate'] = pd.to_datetime(parks_hazards_subset['LastFieldInspectionDate'])\n",
        "parks_hazards_subset['LastActionDate'] = pd.to_datetime(parks_hazards_subset['LastActionDate'])\n",
        "parks_hazards_subset['AddedDate'] = pd.to_datetime(parks_hazards_subset['AddedDate'])\n",
        "print(parks_hazards_subset.dtypes)\n",
        "\n",
        "print(\"\\n3. Fix missing and invalid values in data.\")\n",
        "print(\"Before fixing null values:\\n{}\".format(parks_hazards_subset.isnull().sum()))\n",
        "#We already fixed SignedOff above, but LastFieldInspectionDate, LastActionDate, and OtherComments need\n",
        "parks_hazards_subset['LastFieldInspectionDate'].fillna(parks_hazards_subset['LastActionDate'], inplace = True)\n",
        "parks_hazards_subset['OtherComments'].fillna('N/A', inplace = True)\n",
        "parks_hazards_subset['AddedDate'].fillna(parks_hazards_subset['LastActionDate'], inplace = True)\n",
        "parks_hazards_subset['Feature'].fillna('N/A', inplace = True)\n",
        "parks_hazards_subset['LastActionDate'].fillna(parks_hazards_subset['AddedDate'], inplace = True)\n",
        "print(\"After fixing null values expect WorkOrderNumber:\\n{}\".format(parks_hazards_subset.isnull().sum()))\n",
        "\n",
        "print(\"\\n4. Create new columns based on existing columns or calculations.\")\n",
        "import datetime\n",
        "#Add a column that shows the time between AddedDate to LastFieldInspectionDate: TimeSinceLastFieldInspection\n",
        "parks_hazards_subset['TimeSinceLastFieldInspection'] = parks_hazards_subset['LastFieldInspectionDate'] - parks_hazards_subset['AddedDate']\n",
        "#Add a column that shows the time between AddedDate to LastActionDate: TimeSinceLastAction\n",
        "parks_hazards_subset['TimeSinceLastAction'] = parks_hazards_subset['LastActionDate'] - parks_hazards_subset['AddedDate']\n",
        "#print(parks_hazards_subset.head(1))\n",
        "print(parks_hazards_subset.sort_values(by = 'TimeSinceLastAction', ascending = False).head())\n",
        "\n",
        "print(\"\\n5. Drop column(s) from your dataset.\")\n",
        "print(\"There are {} columns in this dataset.\".format(parks_hazards_subset.shape[1]))\n",
        "#orgtbl holds the same data as SignedOff & WorkOrderNumber as very few rows use it (they can add it to OtherComments if there is one)\n",
        "parks_hazards_subset['OtherComments'] = parks_hazards_subset['OtherComments'] + ' ' + parks_hazards_subset['WorkOrderNumber']\n",
        "parks_hazards_subset.drop(['orgtbl', 'WorkOrderNumber'], axis=1, inplace=True)\n",
        "print(\"There are {} columns after getting rid of orgtbl.\".format(parks_hazards_subset.shape[1]))\n",
        "print(list(parks_hazards_subset))\n",
        "\n",
        "print(\"\\n6. Drop a row(s) from your dataset.\")\n",
        "print(\"There are {} rows in this dataset.\".format(parks_hazards_subset.shape[0]))\n",
        "parks_hazards_subset = parks_hazards_subset.drop(parks_hazards_subset.index[[1,2,3]])\n",
        "print(\"There are {} rows after the drop command.\".format(parks_hazards_subset.shape[0]))\n",
        "\n",
        "print(\"\\n7. Sort your data based on multiple variables.\")\n",
        "print(parks_hazards_subset.sort_values(by = ['AddedDate', 'LastActionDate'], ascending = [True, False]).head(10))\n",
        "\n",
        "print(\"\\n8. Filter your data based on some condition.\")\n",
        "#I want to filter and save all non-SignedOff hazard rows\n",
        "nonSignedOff = parks_hazards_subset.loc[parks_hazards_subset['SignedOff'] == False]\n",
        "print(\"There is {} non-SignedOff hazards in this dataset.\".format(nonSignedOff.shape[0]))\n",
        "print(nonSignedOff.head())\n",
        "\n",
        "print(\"\\n9. Convert all the string values to upper or lower cases in one column.\")\n",
        "parks_hazards_subset['Type'] = parks_hazards_subset['Type'].str.lower()\n",
        "print(parks_hazards_subset['Type'].head(5))\n",
        "\n",
        "print(\"10. Check whether numeric values are present in a given column of your dataframe.\")\n",
        "priority_notnull = pd.to_numeric(parks_hazards_subset['Priority'], errors='coerce').notnull().all()\n",
        "print(\"Are there numeric values in parks_hazards_subset['Priority']? {}\".format(priority_notnull))\n",
        "\n",
        "print(\"11. Group your dataset by one column, and get the mean, min, and max values by group: Groupby() & agg() or .apply()\")\n",
        "parks_hazards_types = parks_hazards_subset.groupby('Type')\n",
        "print(\"The groups formed from grouping by Type are:\\n{}\".format(parks_hazards_types['Type'].unique()))\n",
        "#get mean, min, and max values for Priority\n",
        "types_priority = parks_hazards_types.agg({'Priority': ['mean','min', 'max']})\n",
        "print(\"The mean, min, and max values of Priority by Type groups:\\n{}\".format(types_priority))\n",
        "#get mean, min, and max values for TimeSinceLastFieldInspection\n",
        "types_timeSinceLastFieldInspection = parks_hazards_types.agg({'TimeSinceLastFieldInspection': ['mean','min', 'max']})\n",
        "print(\"The mean, min, and max values of TimeSinceLastFieldInspection by Type groups:\\n{}\".format(types_timeSinceLastFieldInspection))\n",
        "#get mean, min, and max values for TimeSinceLastAction\n",
        "types_timeSinceLastAction = parks_hazards_types.agg({'TimeSinceLastAction': ['mean','min', 'max']})\n",
        "print(\"The mean, min, and max values of TimeSinceLastAction by Type groups:\\n{}\".format(types_timeSinceLastAction))\n",
        "\n",
        "\n",
        "print(\"12. Group your dataset by two columns and then sort the aggregated results within the groups.\")\n",
        "parks_hazards_types_feature = parks_hazards_subset.groupby(['Type','Feature'], sort=True)\n",
        "print(\"The groups formed from grouping by Type then Feature are:\\n{}\".format(parks_hazards_types_feature['Type','Feature'].size().reset_index().sort_values(['Type','Feature'], ascending = [True,False])))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu0U4vocrE99",
        "outputId": "b59b55fd-4d11-4895-cbe9-343bdaac37e0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Modify multiple column names.\n",
            "['Type', 'InspectionID', 'TypeKey', 'LastFieldInspectionDate', 'LastActionDate', 'AddedDate', 'OtherComments', 'Priority', 'Feature', 'WorkOrderNumber', 'Extended', 'SignedOff', 'orgtbl']\n",
            "\n",
            "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
            "Type                        object\n",
            "InspectionID                 int64\n",
            "TypeKey                      int64\n",
            "LastFieldInspectionDate     object\n",
            "LastActionDate              object\n",
            "AddedDate                   object\n",
            "OtherComments               object\n",
            "Priority                   float64\n",
            "Feature                     object\n",
            "WorkOrderNumber             object\n",
            "Extended                      bool\n",
            "SignedOff                   object\n",
            "orgtbl                      object\n",
            "dtype: object\n",
            "Type                               object\n",
            "InspectionID                        int64\n",
            "TypeKey                             int64\n",
            "LastFieldInspectionDate    datetime64[ns]\n",
            "LastActionDate             datetime64[ns]\n",
            "AddedDate                  datetime64[ns]\n",
            "OtherComments                      object\n",
            "Priority                          float64\n",
            "Feature                            object\n",
            "WorkOrderNumber                    object\n",
            "Extended                             bool\n",
            "SignedOff                          object\n",
            "orgtbl                             object\n",
            "dtype: object\n",
            "\n",
            "3. Fix missing and invalid values in data.\n",
            "Before fixing null values:\n",
            "Type                          0\n",
            "InspectionID                  0\n",
            "TypeKey                       0\n",
            "LastFieldInspectionDate     285\n",
            "LastActionDate                7\n",
            "AddedDate                   878\n",
            "OtherComments               596\n",
            "Priority                      9\n",
            "Feature                      15\n",
            "WorkOrderNumber            6447\n",
            "Extended                      0\n",
            "SignedOff                     0\n",
            "orgtbl                        0\n",
            "dtype: int64\n",
            "After fixing null values expect WorkOrderNumber:\n",
            "Type                          0\n",
            "InspectionID                  0\n",
            "TypeKey                       0\n",
            "LastFieldInspectionDate       7\n",
            "LastActionDate                0\n",
            "AddedDate                     0\n",
            "OtherComments                 0\n",
            "Priority                      9\n",
            "Feature                       0\n",
            "WorkOrderNumber            6447\n",
            "Extended                      0\n",
            "SignedOff                     0\n",
            "orgtbl                        0\n",
            "dtype: int64\n",
            "\n",
            "4. Create new columns based on existing columns or calculations.\n",
            "      Type  InspectionID  TypeKey LastFieldInspectionDate  \\\n",
            "88959   IA        111165    94210              2020-09-11   \n",
            "28621   IA         92237    70401              2019-11-07   \n",
            "51800   IA        106271    88321              2021-07-28   \n",
            "29199   IA         92237    70406              2019-03-29   \n",
            "53786   IA        107230    89372              2021-07-30   \n",
            "\n",
            "               LastActionDate           AddedDate  \\\n",
            "88959 2023-09-21 15:05:50.993 2017-08-21 23:00:00   \n",
            "28621 2019-11-07 13:21:37.323 2014-09-10 23:00:00   \n",
            "51800 2021-08-19 17:48:33.170 2016-11-23 23:00:00   \n",
            "29199 2019-04-03 10:12:15.537 2014-09-10 23:00:00   \n",
            "53786 2021-07-31 10:57:45.733 2017-01-19 23:00:00   \n",
            "\n",
            "                                           OtherComments  Priority  \\\n",
            "88959  Work order submitted - Eric.Handy(8/25/2017 9:...       2.0   \n",
            "28621  Thorns was cut back - Stefon.Parson(11/7/2019 ...       2.0   \n",
            "51800  - Jamal.Patterson(5/13/2017 10:03:07 AM) - eli...       2.0   \n",
            "29199  drain cover was replaced - Stefon.Parson(3/30/...       2.0   \n",
            "53786  - elizabeth.walsack(1/20/2017 4:30:15 PM)crack...       2.0   \n",
            "\n",
            "                   Feature WorkOrderNumber  Extended SignedOff    orgtbl  \\\n",
            "88959      Athletic Fields         2068692     False      True  Resolved   \n",
            "28621  Horticultural Areas             NaN     False      True  Resolved   \n",
            "51800       Paved Surfaces         1473409     False      True  Resolved   \n",
            "29199       Paved Surfaces             NaN     False      True  Resolved   \n",
            "53786       Paved Surfaces         1424856     False      True  Resolved   \n",
            "\n",
            "      TimeSinceLastFieldInspection       TimeSinceLastAction  \n",
            "88959           1116 days 01:00:00 2221 days 16:05:50.993000  \n",
            "28621           1883 days 01:00:00 1883 days 14:21:37.323000  \n",
            "51800           1707 days 01:00:00 1729 days 18:48:33.170000  \n",
            "29199           1660 days 01:00:00 1665 days 11:12:15.537000  \n",
            "53786           1652 days 01:00:00 1653 days 11:57:45.733000  \n",
            "\n",
            "5. Drop column(s) from your dataset.\n",
            "There are 15 columns in this dataset.\n",
            "There are 13 columns after getting rid of orgtbl.\n",
            "['Type', 'InspectionID', 'TypeKey', 'LastFieldInspectionDate', 'LastActionDate', 'AddedDate', 'OtherComments', 'Priority', 'Feature', 'Extended', 'SignedOff', 'TimeSinceLastFieldInspection', 'TimeSinceLastAction']\n",
            "\n",
            "6. Drop a row(s) from your dataset.\n",
            "There are 10000 rows in this dataset.\n",
            "There are 9997 rows after the drop command.\n",
            "\n",
            "7. Sort your data based on multiple variables.\n",
            "          Type  InspectionID  TypeKey LastFieldInspectionDate  \\\n",
            "327         IA         55246    30755              2008-01-31   \n",
            "2611        IA         54991    30509              2008-01-16   \n",
            "5019  Graffiti         55246   143351              2008-02-01   \n",
            "2267  Graffiti         54948   142182              2008-01-15   \n",
            "2286       NBF         55652   144779              2008-02-14   \n",
            "442         IA         55467    30972              2008-04-02   \n",
            "1010  Graffiti         56165   146803              2008-04-02   \n",
            "1275  Graffiti         55400   143919              2008-03-30   \n",
            "3242        IA         56216    31576              2008-03-03   \n",
            "394         IA         56060    31453              2008-04-06   \n",
            "\n",
            "              LastActionDate               AddedDate OtherComments  Priority  \\\n",
            "327  2008-04-04 10:37:38.060 2008-04-04 10:37:38.060           NaN       2.0   \n",
            "2611 2008-04-04 11:30:11.450 2008-04-04 11:30:11.450           NaN       2.0   \n",
            "5019 2008-04-04 13:01:41.293 2008-04-04 13:01:41.293           NaN       0.0   \n",
            "2267 2008-04-04 13:10:30.700 2008-04-04 13:10:30.700           NaN       0.0   \n",
            "2286 2008-04-04 16:22:40.640 2008-04-04 16:22:40.640           NaN       0.0   \n",
            "442  2008-04-05 08:01:01.293 2008-04-05 08:01:01.293           NaN       2.0   \n",
            "1010 2008-04-05 09:00:37.500 2008-04-05 09:00:37.500           NaN       0.0   \n",
            "1275 2008-04-07 08:53:21.000 2008-04-07 08:53:21.000           NaN       0.0   \n",
            "3242 2008-04-07 12:58:10.280 2008-04-07 12:58:10.280           NaN       2.0   \n",
            "394  2008-04-07 13:53:38.140 2008-04-07 13:53:38.140           NaN       2.0   \n",
            "\n",
            "             Feature  Extended SignedOff TimeSinceLastFieldInspection  \\\n",
            "327          Benches     False      True    -65 days +13:22:21.940000   \n",
            "2611          Litter     False      True    -80 days +12:29:48.550000   \n",
            "5019        Graffiti     False      True    -64 days +10:58:18.707000   \n",
            "2267        Graffiti     False      True    -81 days +10:49:29.300000   \n",
            "2286          Litter     False      True    -51 days +07:37:19.360000   \n",
            "442   Play Equipment     False      True     -4 days +15:58:58.707000   \n",
            "1010        Graffiti     False      True     -4 days +14:59:22.500000   \n",
            "1275        Graffiti     False      True            -9 days +15:06:39   \n",
            "3242         Benches     False      True    -36 days +11:01:49.720000   \n",
            "394           Litter     False      True     -2 days +10:06:21.860000   \n",
            "\n",
            "     TimeSinceLastAction  \n",
            "327               0 days  \n",
            "2611              0 days  \n",
            "5019              0 days  \n",
            "2267              0 days  \n",
            "2286              0 days  \n",
            "442               0 days  \n",
            "1010              0 days  \n",
            "1275              0 days  \n",
            "3242              0 days  \n",
            "394               0 days  \n",
            "\n",
            "8. Filter your data based on some condition.\n",
            "There is 0 non-SignedOff hazards in this dataset.\n",
            "Empty DataFrame\n",
            "Columns: [Type, InspectionID, TypeKey, LastFieldInspectionDate, LastActionDate, AddedDate, OtherComments, Priority, Feature, Extended, SignedOff, TimeSinceLastFieldInspection, TimeSinceLastAction]\n",
            "Index: []\n",
            "\n",
            "9. Convert all the string values to upper or lower cases in one column.\n",
            "73159          ia\n",
            "4519     graffiti\n",
            "68610          ia\n",
            "48475          ia\n",
            "86657          ia\n",
            "Name: Type, dtype: object\n",
            "10. Check whether numeric values are present in a given column of your dataframe.\n",
            "Are there numeric values in parks_hazards_subset['Priority']? False\n",
            "11. Group your dataset by one column, and get the mean, min, and max values by group: Groupby() & agg() or .apply()\n",
            "The groups formed from grouping by Type are:\n",
            "Type\n",
            "drinking fountain    [drinking fountain]\n",
            "graffiti                      [graffiti]\n",
            "graffiti hazard        [graffiti hazard]\n",
            "ia                                  [ia]\n",
            "nbf                                [nbf]\n",
            "spray showers            [spray showers]\n",
            "Name: Type, dtype: object\n",
            "The mean, min, and max values of Priority by Type groups:\n",
            "                  Priority          \n",
            "                      mean  min  max\n",
            "Type                                \n",
            "drinking fountain  0.00000  0.0  0.0\n",
            "graffiti           0.00000  0.0  0.0\n",
            "graffiti hazard    2.00000  2.0  2.0\n",
            "ia                 1.93985  1.0  2.0\n",
            "nbf                0.00000  0.0  0.0\n",
            "spray showers      0.00000  0.0  0.0\n",
            "The mean, min, and max values of TimeSinceLastFieldInspection by Type groups:\n",
            "                    TimeSinceLastFieldInspection                             \\\n",
            "                                            mean                        min   \n",
            "Type                                                                          \n",
            "drinking fountain   -21 days +01:52:51.743937500  -88 days +10:12:55.407000   \n",
            "graffiti          -2303 days +07:34:51.572107296       -5584 days +01:00:00   \n",
            "graffiti hazard      -1 days +22:23:23.231109966 -304 days +07:50:19.190000   \n",
            "ia                    25 days 20:44:06.273730841 -733 days +09:02:02.610000   \n",
            "nbf               -1768 days +22:24:37.167491808       -5562 days +01:00:00   \n",
            "spray showers       -25 days +11:40:08.643333334  -66 days +11:46:18.207000   \n",
            "\n",
            "                                            \n",
            "                                       max  \n",
            "Type                                        \n",
            "drinking fountain          0 days 00:00:00  \n",
            "graffiti                   0 days 00:00:00  \n",
            "graffiti hazard          619 days 01:00:00  \n",
            "ia                      1883 days 01:00:00  \n",
            "nbf                        0 days 00:00:00  \n",
            "spray showers     -2 days +15:20:11.033000  \n",
            "The mean, min, and max values of TimeSinceLastAction by Type groups:\n",
            "                             TimeSinceLastAction                              \\\n",
            "                                            mean                         min   \n",
            "Type                                                                           \n",
            "drinking fountain                0 days 00:00:00             0 days 00:00:00   \n",
            "graffiti          -2270 days +21:06:34.726738208 -5560 days +14:16:56.077000   \n",
            "graffiti hazard       11 days 15:26:46.706386597             0 days 00:00:00   \n",
            "ia                    36 days 19:40:46.988348714    -1 days +13:31:11.370000   \n",
            "nbf               -1738 days +22:21:34.773442624 -5542 days +10:46:59.390000   \n",
            "spray showers                    0 days 00:00:00             0 days 00:00:00   \n",
            "\n",
            "                                             \n",
            "                                        max  \n",
            "Type                                         \n",
            "drinking fountain           0 days 00:00:00  \n",
            "graffiti                    0 days 00:00:00  \n",
            "graffiti hazard    619 days 16:43:24.863000  \n",
            "ia                2221 days 16:05:50.993000  \n",
            "nbf                         0 days 00:00:00  \n",
            "spray showers               0 days 00:00:00  \n",
            "12. Group your dataset by two columns and then sort the aggregated results within the groups.\n",
            "The groups formed from grouping by Type then Feature are:\n",
            "                 Type              Feature     0\n",
            "0   drinking fountain                    Z    16\n",
            "1            graffiti             Graffiti   233\n",
            "3     graffiti hazard                  N/A     1\n",
            "2     graffiti hazard             Graffiti   581\n",
            "21                 ia                Weeds   172\n",
            "20                 ia         Water Bodies    24\n",
            "19                 ia                Trees  1833\n",
            "18                 ia               Trails    84\n",
            "17                 ia            Sidewalks   702\n",
            "16                 ia       Safety Surface   384\n",
            "15                 ia       Play Equipment   301\n",
            "14                 ia       Paved Surfaces  2347\n",
            "13                 ia                  N/A     6\n",
            "12                 ia               Litter   952\n",
            "11                 ia                Lawns   416\n",
            "10                 ia                  Ice    82\n",
            "9                  ia  Horticultural Areas    53\n",
            "8                  ia                Glass    94\n",
            "7                  ia               Fences   509\n",
            "6                  ia            Buildings     2\n",
            "5                  ia              Benches  1019\n",
            "4                  ia      Athletic Fields   122\n",
            "23                nbf                  N/A     8\n",
            "22                nbf               Litter    53\n",
            "24      spray showers                    Z     3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-933a10510baf>:89: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  print(\"The groups formed from grouping by Type then Feature are:\\n{}\".format(parks_hazards_types_feature['Type','Feature'].size().reset_index().sort_values(['Type','Feature'], ascending = [True,False])))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions**  \n",
        "\n",
        "After exploring your dataset, I now have a clearer understanding of immediante action hazards. They can typically smaller non life-threatening hazards that can be, not always, deal with in a short timeframe. The most interesting part to be was the mean, min, and max for the new time difference columns I created. I was able to see which hazard types and features get dealt with the quickest compared to others. If I had more time, I would have liked to further invest that by doing more summary statistics and visualized data. Also, since this dataset has old and very recent records, I would want to look more at response timeframes across different years. Have it gotten easier or harder to fix different hazards?"
      ],
      "metadata": {
        "id": "fmYjoe5IKVAt"
      }
    }
  ]
}